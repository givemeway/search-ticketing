{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the text documents\n",
    "doc1 = open('document1.txt').read()\n",
    "doc2 = open('document2.txt').read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Compute the TF-IDF vectors for the documents\n",
    "tfidf_matrix = vectorizer.fit_transform([doc1, doc2])\n",
    "\n",
    "# Compute the cosine similarity between the documents\n",
    "similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)\n",
    "\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a57ab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class=\"thread-entry response avatar\" # agent response\n",
    "class=\"thread-entry note avatar\" # agent note\n",
    "class=\"thread-entry message avatar\" # user response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ad290",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Load the text documents\n",
    "doc1 = open('document1.txt').read()\n",
    "doc2 = open('document2.txt').read()\n",
    "\n",
    "# Tokenize the documents into sentences\n",
    "sentences1 = sent_tokenize(doc1)\n",
    "sentences2 = sent_tokenize(doc2)\n",
    "\n",
    "# Find the sentence you want to search for in document2\n",
    "search_sentence = sentences1[0] # Change this to the index of the sentence you want to search for\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Compute the TF-IDF vectors for the sentences\n",
    "tfidf_matrix = vectorizer.fit_transform([search_sentence] + sentences2)\n",
    "\n",
    "# Compute the cosine similarity between the search sentence and each sentence in document2\n",
    "similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])\n",
    "\n",
    "# Find the index of the most similar sentence in document2\n",
    "most_similar_index = similarity.argmax()\n",
    "\n",
    "# Print the most similar sentence from document2\n",
    "print(sentences2[most_similar_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8095e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Load the text documents\n",
    "doc1 = open('document1.txt').read()\n",
    "doc2 = open('document2.txt').read()\n",
    "\n",
    "# Tokenize the documents into sentences using spaCy\n",
    "sentences1 = [sent.text for sent in nlp(doc1).sents]\n",
    "sentences2 = [sent.text for sent in nlp(doc2).sents]\n",
    "\n",
    "# Find the sentence you want to search for in document2\n",
    "search_sentence = sentences1[0] # Change this to the index of the sentence you want to search for\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Compute the TF-IDF vectors for the sentences\n",
    "tfidf_matrix = vectorizer.fit_transform([search_sentence] + sentences2)\n",
    "\n",
    "# Compute the cosine similarity between the search sentence and each sentence in document2\n",
    "similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])\n",
    "\n",
    "# Find the index of the most similar sentence in document2\n",
    "most_similar_index = similarity.argmax()\n",
    "\n",
    "# Print the most similar sentence from document2\n",
    "print(sentences2[most_similar_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6743e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the text documents\n",
    "doc1 = open('document1.txt').read()\n",
    "doc2 = open('document2.txt').read()\n",
    "\n",
    "# Tokenize the documents into sentences\n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b')\n",
    "sentences1 = vectorizer.build_tokenizer()(doc1)\n",
    "sentences2 = vectorizer.build_tokenizer()(doc2)\n",
    "\n",
    "# Find the sentence you want to search for in document2\n",
    "search_sentence = sentences1[0] # Change this to the index of the sentence you want to search for\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Compute the TF-IDF vectors for the sentences\n",
    "tfidf_matrix = vectorizer.fit_transform([search_sentence] + sentences2)\n",
    "\n",
    "# Compute the cosine similarity between the search sentence and each sentence in document2\n",
    "similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])\n",
    "\n",
    "# Find the index of the most similar sentence in document2\n",
    "most_similar_index = similarity.argmax()\n",
    "\n",
    "# Print the most similar sentence from document2\n",
    "print(sentences2[most_similar_index])\n",
    "similarity_value = similarity[0, most_similar_index]\n",
    "print(similarity_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e186f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from itertools import zip_longest\n",
    "\n",
    "import sqlite3,requests\n",
    "from bs4 import BeautifulSoup\n",
    "headers = {\n",
    "        'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.45 Safari/537.36\"\n",
    "    }\n",
    "login_data = {\n",
    "        'do': \"scplogin\",\n",
    "        'userid': \"sandeep.kumar@idrive.com\",\n",
    "        'passwd': \"\",\n",
    "        'submit': ''\n",
    "        }\n",
    "\n",
    "\n",
    "def ticket_session(name,secret):\n",
    "    global headers\n",
    "    with requests.Session() as s:\n",
    "        url = \"https://ticket.idrive.com/scp/login.php\"\n",
    "        try:\n",
    "            r = s.get(url,headers=headers)\n",
    "            if r.status_code == 403:\n",
    "                return 403 # unauthorized\n",
    "            else:\n",
    "                return build_header(r,s,url,name,secret)  \n",
    "        except requests.exceptions.HTTPError as errh:\n",
    "                return (request_errors[0],errh)\n",
    "        except requests.exceptions.ConnectionError as errc:\n",
    "                return (request_errors[1],errc)\n",
    "        except requests.exceptions.Timeout as errt:\n",
    "                return (request_errors[2],errt)\n",
    "        except requests.exceptions.RequestException as err:\n",
    "                return (request_errors[3],err)\n",
    "            \n",
    "def build_header(r,s,url,username,password):\n",
    "                global login_data\n",
    "                try:\n",
    "                    soup = BeautifulSoup(r.content,'html5lib')\n",
    "                    login_data['__CSRFToken__'] = soup.find('input',attrs={'name':'__CSRFToken__'})['value']\n",
    "                    login_data['userid']= username\n",
    "                    login_data['passwd']= password\n",
    "                    r = s.post(url,data=login_data,headers=headers)\n",
    "                    if r.status_code == 200:\n",
    "                        return s\n",
    "                    else:\n",
    "                    \n",
    "                        return 422 # login failed\n",
    "                except Exception as e:\n",
    "                    return ('DB Exception-2',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8015fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "def search_query(s,url):\n",
    "    try:\n",
    "        query = '\\\"{}\\\"'.format(urllib.parse.quote_plus(search.strip()))\n",
    "        r  = s.get(url,headers=headers)\n",
    "        return r\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "                return 'error-http'\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "                return 'error-connection'\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "                return 'error-timeout'\n",
    "    except requests.exceptions.RequestException as err:\n",
    "                return 'error-requestionException'\n",
    "    except Exception as e:  \n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e2aed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ticket_url(soup,ticket):\n",
    "    url = \"\"\n",
    "    for tr in soup.select(\".list tbody tr\"):\n",
    "        for td in tr.select(\"td:nth-child(2)\"):\n",
    "            if(td.get_text().strip() == ticket):\n",
    "                url = \"https://ticket.idrive.com/scp/\" + td.find_all(\"a\")[0]['href']\n",
    "                break\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "504f879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ticket_session('sandeep.kumar@idrive.com','sandy86kumar')\n",
    "searchURL = \"https://ticket.idrive.com/scp/tickets.php?a=search&search-type=&query=%22sandeep.kumar%40idriveinc.com%22\"\n",
    "ticketSearch = search_query(session,searchURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "256d3ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ticket.idrive.com/scp/tickets.php?id=1306960'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(ticketSearch.content,'html5lib')\n",
    "extract_ticket_url(soup,'ID677184755')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89d7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ticket_session('sandeep.kumar@idrive.com','sandy86kumar')\n",
    "url = \"https://ticket.idrive.com/scp/tickets.php?id=1293259\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd61c83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket = search_query(session,url)\n",
    "ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(ticket.content,'html5lib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1b6d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = \"\"\"\n",
    "USER FEEDBACK FROM IDRIVE WEBSITE:\n",
    "IDrive Username:\n",
    "User's Current plan:\n",
    "User's e-mail address: turk714@outlook.com\n",
    "User's Contact Phone Number: 7026722737\n",
    "User's Operating System: Mac OS\n",
    "User's Browser: Apple Safari\n",
    "IDrive Program Used: IDrive for iPad\n",
    "User's technical issues/comments/suggestions: I’ve been trying to cancel my subscription, but couldn’t get any help. There’s no contact information on this iPad. How can I cancel my subscription? I can’t afford it at this time. I’m retired and on a fixed income. Please cancel if possible.\n",
    "Thanks for your time, Robert\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752465d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_search(soup):\n",
    "    list_obj ={}\n",
    "    url = \"https://ticket.idrive.com/scp/\"\n",
    "    for count,tr in enumerate(soup.find_all('tr')):\n",
    "        search_obj={}\n",
    "        for i,td in enumerate(tr.find_all('td')):\n",
    "            if i==1:\n",
    "                search_obj['ticket'] = td.text.strip()\n",
    "                for a in td.find_all('a'):\n",
    "                    search_obj['ticketUrl'] = url + a.get('href')\n",
    "            elif i==2:\n",
    "                search_obj['created']= td.text.strip()\n",
    "            elif i==3:\n",
    "                children = td.findChildren('div',recursive=True)\n",
    "                for child in children:\n",
    "                    search_obj['subject'] = child.text.strip()\n",
    "            else:\n",
    "                continue\n",
    "        if len(search_obj):       \n",
    "            list_obj[count] = search_obj\n",
    "    return list_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_notes(soup,selector1,selector2):\n",
    "    # .thread-entry.message .header  --> user response\n",
    "    # .thread-entry.note .header --> notes\n",
    "    # .thread-event.action .faded.description  --> thread action    \n",
    "    # .thread-entry.response .header     --> agent response\n",
    "    notes = []\n",
    "    for b,time in zip_longest(soup.select(selector1),soup.select(selector2)):\n",
    "#         print(b.get_text().strip(),time.get_text().strip())\n",
    "        notes.append({\"agent\":b.get_text().strip(),\\\n",
    "                      \"time\":time.get_text().strip(),\\\n",
    "                      \"timestamp\": datetime.strptime(time.get_text().strip(),\\\n",
    "                                 '%m/%d/%y, %I:%M %p').timestamp()    \n",
    "                     })\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16198de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ticket_events(soup,selector1,selector2,selector3):\n",
    "    # .thread-entry.message .header  --> user response\n",
    "    # .thread-entry.note .header --> notes\n",
    "    # .thread-event.action .faded.description  --> thread action    \n",
    "    # .thread-entry.response .header     --> agent response\n",
    "    events = []\n",
    "    for b,strong,time in zip_longest(soup.select(selector1),soup.select(selector2),soup.select(selector3)):\n",
    "#         print(b.get_text().strip(),strong.get_text(),time.get_text().strip())\n",
    "        events.append({\"agent\":b.get_text().strip() if b is not None else None,\\\n",
    "                       \"department\":strong.get_text().strip() if strong is not None else None,\\\n",
    "                       \"time\":time.get_text().strip() if time is not None else None\\\n",
    "                      })\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector1 = \".thread-entry.note .header b\"\n",
    "selector2 = \".thread-entry.note .header time\"\n",
    "notes = find_notes(soup,selector1,selector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c315fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector1 = \".thread-event.action .faded.description b\"\n",
    "selector2 = \".thread-event.action .faded.description strong\"\n",
    "selector3 = \".thread-event.action .faded.description time\"\n",
    "events = find_ticket_events(soup,selector1,selector2,selector3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9874dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "selector = \".thread-event.action .faded.description:has(>b:first-child):has(>time):has(>strong)\"\n",
    "datetime.strptime(datestring,'%d/%m/%y, %I:%M %p').timestamp()\n",
    "def find_ticket_events(soup,selector):\n",
    "    events = []\n",
    "    for strong in soup.select(selector):\n",
    "        item = {  \"agent\"     :   strong.select(\"b\")[0].get_text().strip(),\\\n",
    "                  \"department\":   strong.select(\"strong\")[0].get_text().strip(),\\\n",
    "                  \"time\"      :   strong.select(\"time\")[0].get_text().strip(),\\\n",
    "                  \"timestamp\" :   datetime.strptime(strong.select(\"time\")[0].get_text().strip(),\\\n",
    "                                 '%m/%d/%y, %I:%M %p').timestamp()  \n",
    "                }\n",
    "        events.append(item)\n",
    "    return events\n",
    "events = find_ticket_events(soup,selector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "events[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd088564",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "escalated = None\n",
    "while i < len(events):\n",
    "    item = events.pop()\n",
    "    if item[\"department\"] in ['IBWin (EVS)']:\n",
    "        escalated = item\n",
    "        break\n",
    "    i += 1\n",
    "escalated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a09cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "i = 0\n",
    "dev = None\n",
    "diff = float(\"inf\")\n",
    "while i < len(notes):\n",
    "    item = notes.pop()\n",
    "    if item['timestamp'] > escalated['timestamp'] and item['agent'] in ['Bala Murugan',\"Punith B M\"]:\n",
    "        diff = datetime.fromtimestamp(item['timestamp']) - datetime.fromtimestamp(escalated['timestamp'])\n",
    "        dev = item\n",
    "        break\n",
    "    i += 1\n",
    "if math.isinf(diff):\n",
    "    diff = datetime.now() - datetime.fromtimestamp(escalated['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772075ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c98678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646949e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "datestring = '6/10/23, 12:17 PM'\n",
    "datestring2 = '5/17/23, 12:01 PM'\n",
    "\n",
    "timestamp = datetime.strptime(datestring2,'%m/%d/%y, %I:%M %p').timestamp()\n",
    "timestamp\n",
    "datetime.fromtimestamp(1684305060)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b84c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c29c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.timestamp(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ticket.idrive.com/scp/ajax.php/tickets/1150913/transfer  -->departments\n",
    "# https://ticket.idrive.com/scp/ajax.php/tickets/1293259/assign/agents --> agents in a department\n",
    "# https://ticket.idrive.com/scp/ajax.php/tickets/1150913/assign/teams --> agents in all the teams\n",
    "# https://ticket.idrive.com/scp/tickets.php?id=1293259\n",
    "agentsURL = \"https://ticket.idrive.com/scp/ajax.php/tickets/1293259/assign/agents\"\n",
    "departMentURL = \"https://ticket.idrive.com/scp/ajax.php/tickets/1150913/transfer\"\n",
    "def agents_in_department(url):\n",
    "    ticket = search_query(session,url)\n",
    "    soup = BeautifulSoup(ticket.content,'html5lib')\n",
    "    dropdownitems = []\n",
    "    for select in soup.select(\".form-simple select\"):\n",
    "        for option in select.find_all(\"option\"):\n",
    "            dropdownitems.append(option.get_text().strip().split(\"/\")[-1].strip())\n",
    "    \n",
    "    return dropdownitems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b86c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = agents_in_department(agentsURL)\n",
    "department = agents_in_department(departMentURL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb31263",
   "metadata": {},
   "outputs": [],
   "source": [
    "department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d4493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dc5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_search(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ebf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,response in enumerate(soup.find_all(\"div\",class_=\"thread-entry message avatar\")):\n",
    "    for body in response.find_all(\"div\",class_=\"thread-body\"):\n",
    "        doc1 = body.text.strip()\n",
    "        similarity = findSimilarityScore(doc2,doc1)\n",
    "        print(similarity[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd4e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c132ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def findSimilarityScore(doc1,doc2):\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Compute the TF-IDF vectors for the documents\n",
    "    tfidf_matrix = vectorizer.fit_transform([doc1, doc2])\n",
    "\n",
    "    # Compute the cosine similarity between the documents\n",
    "    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)\n",
    "    \n",
    "    return similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mailbox\n",
    "import re\n",
    "regex = re.compile(r'''([a-zA-Z0-9.!#$%&'*+-/=?^_`{|}~-]+@[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)*)''', re.MULTILINE)\n",
    "\n",
    "mbox = mailbox.mbox('mbox.mbox')\n",
    "for message in mbox:\n",
    "    if \"turk714@outlook.com\" in regex.findall(message[\"From\"]):\n",
    "        for part in message.get_payload():\n",
    "                print(part)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91eabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mailbox\n",
    "import re\n",
    "import base64\n",
    "regex = re.compile(r'''([a-zA-Z0-9.!#$%&'*+-/=?^_`{|}~-]+@[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)*)''', re.MULTILINE)\n",
    "sizeRegex = re.compile(r'''\\bsize=[0-9]+\\b''',re.MULTILINE)\n",
    "mbox = mailbox.mbox('mbox.mbox')\n",
    "attachments = []\n",
    "for message in mbox:\n",
    "        if message.is_multipart():\n",
    "            for part in message.get_payload():\n",
    "                if part.get_content_disposition() == 'attachment':\n",
    "                    try:\n",
    "                        #  Extract the size of the attachment from the \"Content-Length\" header field\n",
    "\n",
    "                        attachment = sizeRegex.findall(part['Content-Disposition'])\n",
    "                        if len(attachment)>0:\n",
    "                            attachments.append(attachment[0].split(\"=\")[-1])\n",
    "                        else:\n",
    "                            attachment_data = part.get_payload(decode=True)\n",
    "                            size = len(base64.b64decode(attachment_data))\n",
    "                            attachments.append(size)\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "        else:\n",
    "            if message.get_content_disposition() == 'attachment':\n",
    "                try:\n",
    "                    #  Extract the size of the attachment from the \"Content-Length\" header field\n",
    "#                     attachment_data = message.get_payload(decode=True)\n",
    "#                     size = len(base64.b64decode(attachment_data))\n",
    "                    attachment = sizeRegex.findall(part['Content-Disposition'])\n",
    "                    if len(attachment)>0:\n",
    "                        attachments.append(attachment[0].split(\"=\")[-1])\n",
    "                    else:\n",
    "                        attachment_data = message.get_payload(decode=True)\n",
    "                        size = len(base64.b64decode(attachment_data))\n",
    "                        attachments.append(size)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ad6341",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(attachments))\n",
    "attachments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbbd8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mbox\n",
    "mboxObj = mailbox.mbox(\"mbox.mbox\")\n",
    "for msg in mboxObj:\n",
    "    if \"asher@bsu-inc.com\" in regex.findall(msg[\"From\"]):\n",
    "        email_data = mbox.GmailMboxMessage(msg)\n",
    "        for content in email_data.read_email_payload():\n",
    "            if content[0] == \"text/plain\":\n",
    "                print(\"**********************************************\")\n",
    "                print(content[2])\n",
    "                print(\"***********************************************\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c18c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
